{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a doc2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're going to do in this exercise:\n",
    "* load a pre-trained doc2vec model\n",
    "* use it to infer document embeddings for our test set\n",
    "* cluster the documents based on the embeddings cosine distances\n",
    "* use t-SNE to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import doc2vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.cluster import kmeans\n",
    "from nltk.cluster import util\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic settings\n",
    "HOMEDIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_FILE = os.path.join(HOMEDIR, \"data/corpus_train.txt\")\n",
    "MODEL_FILE_DM = os.path.join(HOMEDIR, \"models/doc2vec_DM_v20171229.bin\")\n",
    "MODEL_FILE_DBOW = os.path.join(HOMEDIR, \"models/doc2vec_DBOW_v20171229.bin\")\n",
    "\n",
    "NUM_CLUSTERS = 20  # yes, you can change this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read corpus file and parse into token lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CORPUS_FILE, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    docs = [simple_preprocess(line, deacc=False, min_len=1) for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read existing model and use it to derive document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "# model = doc2vec.Doc2Vec.load(MODEL_FILE_DM)  # DM model chosen by default\n",
    "# model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)  # only keep what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'delete_temporary_training_data' from 'gensim.utils' (c:\\Users\\uSER\\anaconda3\\lib\\site-packages\\gensim\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\uSER\\Documents\\GitHub\\doc2vec-workshop\\doc2vec-02-topics.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/uSER/Documents/GitHub/doc2vec-workshop/doc2vec-02-topics.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m delete_temporary_training_data\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uSER/Documents/GitHub/doc2vec-workshop/doc2vec-02-topics.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m doc2vec\u001b[39m.\u001b[39mDoc2Vec\u001b[39m.\u001b[39mload(MODEL_FILE_DM)  \u001b[39m# Load pre-trained model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uSER/Documents/GitHub/doc2vec-workshop/doc2vec-02-topics.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Delete temporary training data\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'delete_temporary_training_data' from 'gensim.utils' (c:\\Users\\uSER\\anaconda3\\lib\\site-packages\\gensim\\utils.py)"
     ]
    }
   ],
   "source": [
    "# *DO NOT RUN*\n",
    "from gensim.utils import delete_temporary_training_data\n",
    "\n",
    "model = doc2vec.Doc2Vec.load(MODEL_FILE_DM)  # Load pre-trained model\n",
    "\n",
    "# Delete temporary training data\n",
    "delete_temporary_training_data(model, keep_doctags_vectors=True, keep_inference=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uSER\\AppData\\Local\\Temp\\ipykernel_49412\\3892327324.py:9: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs = KeyedVectors(vector_size=model.vector_size)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = doc2vec.Doc2Vec.load(MODEL_FILE_DM)\n",
    "\n",
    "# Getting errors, hence, manually deleting errors\n",
    "# del model.wv\n",
    "# del model.dv\n",
    "# del model.docvecs \n",
    "model.docvecs = KeyedVectors(vector_size=model.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "**_Exercise 2: Combine DM and DBOW models_**\n",
    "\n",
    "**Note: don't start this exercise yet! First complete the rest of the notebook, then return here to do this exercise!**\n",
    "\n",
    "The authors of the paper suggest that combining the DM and the DBOW model works better than any single one. Do this by concatenating (you could also try to averaging or summing) the embeddings from both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "solution": "shown",
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "solution": "shown",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "# del model\n",
    "model_dm = doc2vec.Doc2Vec.load(MODEL_FILE_DM)\n",
    "model_dbow = doc2vec.Doc2Vec.load(MODEL_FILE_DBOW)\n",
    "\n",
    "infer_epochs = 1000\n",
    "\n",
    "docvecs_dm = [model_dm.infer_vector(d, alpha=0.01, epochs=infer_epochs) for d in docs]\n",
    "docvecs_dbow = [model_dbow.infer_vector(d, alpha=0.01, epochs=infer_epochs) for d in docs]\n",
    "\n",
    "docvecs = [docvecs_dm[i] + docvecs_dbow[i] for i in range(len(docs))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown"
   },
   "source": [
    "=========== end of exercise ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer document vectors\n",
    "infer_epochs = 1000\n",
    "docvecs = [model.infer_vector(d, alpha=0.01, epochs=infer_epochs) for d in docs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have document vectors, start clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = kmeans.KMeansClusterer(NUM_CLUSTERS, distance=util.cosine_distance, repeats=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments = clusterer.cluster(docvecs, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({9: 976,\n",
       "         7: 5515,\n",
       "         5: 884,\n",
       "         18: 1849,\n",
       "         13: 6582,\n",
       "         12: 1555,\n",
       "         3: 1877,\n",
       "         15: 1278,\n",
       "         11: 1896,\n",
       "         14: 2085,\n",
       "         0: 1189,\n",
       "         16: 946,\n",
       "         8: 1860,\n",
       "         17: 1757,\n",
       "         6: 812,\n",
       "         1: 669,\n",
       "         2: 1680,\n",
       "         10: 1549,\n",
       "         19: 1152,\n",
       "         4: 851})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many documents per cluster?\n",
    "collections.Counter(cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents_in_cluster(cluster_idx):\n",
    "    return [doc for i, doc in enumerate(docs) if cluster_assignments[i] == cluster_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_topics(doc_vec, topic_vecs):\n",
    "    \"\"\"\n",
    "    For a given document, give the topic distribution (softmax probabilities for all topics)\n",
    "    \"\"\"\n",
    "    similarities = [np.dot(doc_vec, topic_vec) for topic_vec in topic_vecs]\n",
    "    return np.exp(similarities) / np.sum(np.exp(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define the topics as the cluster centroids. Then find the nearest-neighbor words to describe the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vecs = clusterer.means()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize topics using t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're going to do now:\n",
    "* reduce 100-dim vector space to 2 dimensions\n",
    "* plot all documents in this 2D space\n",
    "* use color to show the clustering\n",
    "* inspect how close / afar certain documents are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import push_notebook, output_notebook, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uSER\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\uSER\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36962, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_tsne = TSNE(n_components=2, perplexity=30, init='pca').fit_transform(docvecs)\n",
    "docs_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix with topic proportion per doc per topic\n",
    "doc_topic_matrix = [get_document_topics(docvec, topic_vecs) for docvec in docvecs]\n",
    "# select highest topic prob\n",
    "prob_max_topic = np.max(doc_topic_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 colors\n",
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\",\n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\",\n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedata = {\n",
    "    'x': docs_tsne[:, 0],\n",
    "    'y': docs_tsne[:, 1],\n",
    "    'color': colormap[cluster_assignments],\n",
    "    'alpha': prob_max_topic * 50,\n",
    "    'content': lines,\n",
    "    'topic_key': cluster_assignments\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make and show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot = bp.figure(plot_width=1600, plot_height=900,\n",
    "                      title=\"Topics\",\n",
    "                      tools=\"pan,wheel_zoom,box_zoom,reset,hover\",\n",
    "                      x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "tsne_plot.scatter(x='x', \n",
    "                  y='y',\n",
    "                  color='color',\n",
    "                  size='alpha',\n",
    "                  #size=10,\n",
    "                  source=bp.ColumnDataSource(sourcedata)\n",
    "                 )\n",
    "\n",
    "# add hover tooltips\n",
    "hover = tsne_plot.select(dict(type=HoverTool))\n",
    "hover.tooltips = {\"content\": \"@content - topic: @topic_key\"}\n",
    "\n",
    "show(tsne_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ok. Now go back up and start exercise 2 and see if it's an improvement!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
